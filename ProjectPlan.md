**Overview**
	
One of the worst things that a person can do on the road is drink and drive. What we want to look at in our project is the relationship with alcohol consumption in the U.S compared to the records of US traffic fatalities.Our initial predictions are that the states that consume a higher amount of alcohol will have a higher fatality rate. The reason we think that is because when a person drinks alcohol they become impaired increasing their chance of an accident. Our goal is to see if this is reflected within the datasets we chose regarding alcohol consumption and traffic fatalities.
	
**Research Questions
**
In order to help us achieve the goal of our project, we chose a couple of research questions that we believe will help us gain a better perspective on this topic. The first question that we wanted to look at was do states that have a higher alcohol consumption per capita, also have a higher traffic fatality rate? After we look at this, we also want to know if different types of alcoholic beverages differ in traffic fatalities as well. For this, we will look at the question, does states with a higher consumption of higher percentage alcoholic beverages have higher traffic fatality rates? When answering these questions we hope to gain a good understanding of the relationship between alcohol and traffic accidents.

**Team**

Our team consists of two team members, Shoi and Jalen. While we are both going to work collaboratively on some parts, we split up some of the other requirements to maintain efficiency within this project. The sections that we are going to work together on are the data lifestyle, ethical data handling, and reproducibility and transparency. Jalen will work on the data collection and acquisition, storage and organization, workflow automation and provenance, and metadata and data documentation. Shoi will work on extraction and enrichment, data quality, and data cleaning. While some of these parts we are doing separately, we will be discussing problems and checking each otherâ€™s work to create a successful project.

**Datasets**

The two datasets that we chose to integrate and use for this project both come from Kaggle. The first one is called alcohol consumption us. This dataset contains information from the years 1977-2016. This dataset looks at the ethanol consumption of states per capita by looking at different spirits and liquors and how much each state consumes on a yearly basis. The dataset itself appears to be pretty clean at a first glance with not much missing data. The second dataset we looked at looked at US traffic fatality records.This dataset contains information on crashes that involved fatalities occurring in the years 2015-2016. The information includes how many vehicles were involved in the crash, the state that it happened in, how many people were involved, etc. This dataset also appears to be pretty clean, but there are multiple datasets to go along with this. Our plan is to intersect the traffic fatality deaths datasets with the alcohol consumption dataset only looking at the years of 2015-2016. Since the traffic fatality dataset only contains information from the years 2015-2016, we need to only look at data that corresponds to these years. Keeping the years surrounding would be unnecessary as we do not have any traffic records that would go along with these metrics of alcohol consumption.

**Timeline** 

Our project will investigate how state-level alcohol consumption can predict fatal accidents across the US using two data sets, one is Alcohol consumption by state (1977-2016) and the other is National Highway Traffic Safety Administration crash dataset (2015). From October 16-20th our task will be to organize the github repository, define contribution workflows, and create a structured directory system for reproducibility. By laying out structured groundwork, contributions will be hassle free. Parallelly we will relate our work to the data lifecycle model and outline the acquisition, cleaning and integration, this will be the preliminary part to the data quality phase. This stage will also contain a review of ethical data handling. This initial stage will be done in collaboration with both Jalen and Shoi contributing to parts of it. For the next week from the 21st to 27th Jalen will start working on the data acquisition scripts and verify integrity. Shoi will start to create metadata and start the initial markdown. From October 28th to November 3rd, the main task at hand will be to clean the data. Shoi will be working on making the datasets compliant with each other while also shortening the alcohol consumption dataset to only include values from 2015 because that is what the fatality dataset contains. From November 4th to 10th Jalen will be responsible for data integration which we will most likely do through SQL join. During this, Shoi will be doing exploratory analysis on both of the datasets. From November 11th to 24th both Jalen and Shoi will be working on developing predictive models, we will most likely use linear regression and correlation analysis. Jalen will be focused on implementing workflows to automate the processes of acquisition, cleaning, and modeling, so that reproducibility could be prevalent. From November 25th to December 6th Shoi will work on finalizing the markdown reports while looking and FAIR compliance as well. Jalen will prepare metadata files and documentation. From December 7th-10th both Shoi and Jalen will review the full project and confirm compliance with all requirements and conduct the final project release. 

**Constraints**

One of the main constraints we have is that our alcohol data set has data from 1977 to 2016 while our accident fatality dataset just has data from 2015 and 2016. This will limit our analysis to just those to years which will reduce its scalability, and strength for long term analysis. Another prominent constraint that we have is that the alcohol consumption dataset is aggregated by state and year while the accident fatality dataset is aggregated by individual crash incidents. This will make the data quality and integration process one of the most tedious processes in the project. Because we will have to aggregate crash incidents and alcohol consumption by state and year which will lead to loss of detail. 

**Gaps**

Some prominent gaps present are that the alcohol consumption data provides details on beverage type and amount of consumption but there is no data in the fatality dataset that says that the accident was alcohol related. This gap could be closed if we used a DUI dataset but by choosing a broader dataset we open the door up for more exploration. Another gap is the lack of social or infrastructure variables such as population density or access to public transport which could affect alcohol consumption and driving habits which could lead to a deeper analysis. 
